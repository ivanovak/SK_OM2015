{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Problem 1 **: *Censored data fitting* (2 points). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" / width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100) (25,) (2,)\n"
     ]
    }
   ],
   "source": [
    "# data for censored fitting problem\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "\n",
    "n = 2;  # dimension of x's\n",
    "M = 25;  # number of non-censored data points\n",
    "K = 100; # total number of points\n",
    "\n",
    "c_true = randn(n)\n",
    "X = randn(n, K)\n",
    "y = np.dot(X.T, c_true) + 0.1 * np.sqrt(n) * randn(K)\n",
    "\n",
    "# Reorder measurements, then censor\n",
    "sort_ind = np.argsort(y)\n",
    "X = X[:, sort_ind];\n",
    "y = y[sort_ind[:M + 1]]\n",
    "D = (y[M - 1]+y[M]) / 2\n",
    "y = y[:M]\n",
    "\n",
    "print X.shape, y.shape, c_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between this problem and a classical least squares is that some of the equations $c_1x_1^i + c_2x_2^i$ should now be at least $D$. We will introduce $K-M$ values $\\Delta y_i$ and will try to fit the model where the error for censored values will be $(c_1x_1^i + c_2x_2^i - D - \\Delta y_i)^2, i > M, \\Delta y_i >= 0$, while for known $y_i (i \\leq M)$ residuals will remain the same $(c_1x_1^i + c_2x_2^i - y_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res:  0.718028040905\n",
      "c estimated:  [[-1.59614111 -0.74665155]] c true: [-1.59610326 -0.72368144]\n"
     ]
    }
   ],
   "source": [
    "# Solution for part a\n",
    "from cvxpy import *\n",
    "\n",
    "c = Variable(2, 1)\n",
    "delta_y = Variable(K - M)\n",
    "tail = D*np.ones(K - M)\n",
    "yn = np.hstack((y, tail))\n",
    "\n",
    "obj = Minimize(norm(X.T*c-yn-vstack(np.zeros(M), delta_y)))\n",
    "constraints = [ delta_y >= 0 ]\n",
    "prob = Problem(obj, constraints)\n",
    "res = prob.solve(solver=SCS)\n",
    "\n",
    "print \"res: \",res\n",
    "print \"c estimated: \", c.value.flatten(), \"c true:\", c_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets fit the model using only the uncensored data and then calculate the relative errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res:  0.717021915971\n",
      "c estimated:  [[-1.59657812 -0.74738524]] c true: [-1.59610326 -0.72368144]\n",
      "Relative error case #1: 0.694949904018\n",
      "Relative error case #2: 0.694844775526\n"
     ]
    }
   ],
   "source": [
    "c2 = Variable(2, 1)\n",
    "\n",
    "obj = Minimize(norm(X[:, :M].T*c2-y))\n",
    "prob = Problem(obj, [])\n",
    "res = prob.solve(solver=SCS)\n",
    "\n",
    "print \"res: \",res\n",
    "print \"c estimated: \", c2.value.flatten(), \"c true:\", c_true\n",
    "\n",
    "print \"Relative error case #1:\", np.linalg.norm(c_true - c.value) / np.linalg.norm(c_true)\n",
    "print \"Relative error case #2:\", np.linalg.norm(c_true - c2.value) / np.linalg.norm(c_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Problem 2 **: *Optimal vehicle speed scheduling (3 points) *-- (additional exercise A3.20 to Boyd and Vandenberghe). \n",
    "\n",
    "A vehicle (say, an airplane) travels along a fixed path of *n* segments, between *n + 1* waypoints labeled *0, . . . , n*. Segment *i* starts at waypoint *i − 1* and terminates at waypoint *i*. The vehicle starts at time *t = 0* at waypoint *0*. It travels over each segment at a constant (nonnegative) speed; *si* is the speed on segment *i*. We have lower and upper limits on the speeds: *smin ≤ s ≤ smax*. The vehicle does not stop at the waypoints; it simply proceeds to the next segment. The travel distance of segment *i* is *di* (which is positive), so the travel time over segment *i* is *di/si*. We let *τi*, *i = 1, . . . , n,* denote the time at which the vehicle arrives at waypoint *i*. The vehicle is required to arrive at waypoint *i*, *for i = 1, . . . , n*, between times *τmin,i* and *τmax,i* , which are given. The vehicle consumes fuel over segment *i* at a rate that depends on its speed *Φ(s_i )=a s_i^2+b s_i+c kg/s*.\n",
    "\n",
    "You are given the data *d* (segment travel distances), *smin* and *smax* (speed bounds), *τmin* and *τmax* (waypoint arrival time bounds), and the the parameters *a*, *b*, and *c* (all parameters are in *veh_speed_sched_data.m*). For the given form of the potentials, find the way to reduce the problem to a convex optimization problem and solve it using CVX (NB: you need not necessarily use one of the “canonical” convex optimization formulations we saw in the course). Use MATLAB command stairs to plot speed vs time for the optimal schedule.  What are relative pros and cons for using convex optimization vs. dynamic programming for such task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "mat_contents = sio.loadmat('veh_sched_data.mat')\n",
    "\n",
    "a = mat_contents['a']\n",
    "b = mat_contents['b']\n",
    "c = mat_contents['c']\n",
    "d = mat_contents['d']\n",
    "n = mat_contents['n']\n",
    "smin = mat_contents['smin']\n",
    "smax = mat_contents['smax']\n",
    "tau_min = mat_contents['tau_min']\n",
    "tau_max = mat_contents['tau_max']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"3.png\" width=\"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__\n",
    "\n",
    "Here is Lagrangian:\n",
    "$$ L(x, \\lambda, \\nu) = p^Tx + \\lambda^T(Ax - b) + \\nu^T(d - Cx)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g(\\lambda, \\nu) = \\min_x{L(x, \\lambda, \\nu)} = min_x{\\left((p^T + \\lambda^TA + \\nu^TC)x - \\lambda^Tb + \\nu^Td\\right)}$$\n",
    "\n",
    "And here is dual problem formulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\max_{\\nu, \\lambda}{-\\lambda^Tb + \\nu^Td}$$\n",
    "$$s.t.: p^T + \\lambda^TA + \\nu^TC = 0$$\n",
    "$$\\lambda \\geq 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"4.png\" width=\"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__\n",
    "\n",
    "$$L(x, \\lambda, \\nu) = f_0(x) + \\lambda_1(-x_1 - 2x_2 + 1) + \\lambda_2(-3x_1 - x_2 + 1) = x_1^2 + x_2^2 - x_1x_2+ \\lambda_1(-x_1 - 2x_2 + 1) + \\lambda_2(-3x_1 - x_2 + 1) $$\n",
    "\n",
    "$$g(\\lambda) = \\min_{x}{L(x, \\lambda)}$$\n",
    "\n",
    "$$\\lambda_i \\geq 0, x = (x_1, x_2)^T$$\n",
    "\n",
    "Dual problem:\n",
    "\n",
    "$$\\max_{\\lambda \\geq 0}g(\\lambda)$$\n",
    "\n",
    "Let's improve our $L$ representation. First let's observe that $L$ is continuous in every point on all the directions as well as infinetely differentiable. Let's find partial derevatives of $L$ w.r.t $x_1$ and $x_2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial x_1} = 2x_1-x_2-\\lambda_1-3\\lambda_2$$\n",
    "$$\\frac{\\partial L}{\\partial x_2} = 2x_2-x_1-2\\lambda_1-\\lambda_2$$\n",
    "\n",
    "since we are minimizing a convex function the following equations should satisfy:\n",
    "\n",
    "$$\\left\\{ \\begin{array}{rl}\n",
    " 2x_1-x_2-\\lambda_1-3\\lambda_2 = 0 \\\\\n",
    " 2x_2-x_1-2\\lambda_1-\\lambda_2 = 0\n",
    "       \\end{array} \\right.$$\n",
    "       \n",
    "lets now substitute $x_{1,2}$ in our Lagrangian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"wolfram.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(x, \\lambda, \\nu) = -\\frac{1}{3}\\left(7t_1^2+17t_2t_1+13t_2^2\\right) + t_1 + t_2, $$\n",
    "where $t_i = \\lambda_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(x,\\lambda,\\nu) = -\\frac{1}{3}t^T\\left( \\begin{array}{ccc}\n",
    "7 & 8.5 \\\\\n",
    "8.5 & 13  \\end{array} \\right)t + t_1 + t_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res:  0.107141954258\n",
      "x:  [[ 0.28571457  0.35714399]]\n",
      "res dual:  0.107140193577\n",
      "lambdas:  [[  2.14091385e-01  -1.08233580e-05]]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cx\n",
    "from cvxpy import *\n",
    "import numpy as np\n",
    "\n",
    "# Initial problem\n",
    "x = Variable(2, 1)\n",
    "Q = np.array([1, -0.5, -0.5, 1]).reshape(2, 2)\n",
    "A = np.array([1, 2, 3, 1]).reshape(2, 2)\n",
    "\n",
    "obj = Minimize(quad_form(x, Q))\n",
    "constraints = [ A*x >= 1 ]\n",
    "prob = Problem(obj, constraints)\n",
    "res = prob.solve(solver=SCS)\n",
    "print \"res: \",res\n",
    "print \"x: \", x.value.flatten()\n",
    "\n",
    "# Dual problem\n",
    "l = Variable(2, 1)\n",
    "Q2 = np.array([7, 8.5, 8.5, 13]).reshape(2, 2)\n",
    "dual_obj = Maximize(-1/3.*quad_form(l, Q2) + l[0] + l[1])\n",
    "constr = [l >= 0]\n",
    "prob = Problem(dual_obj, constr)\n",
    "res = prob.solve(solver=SCS)\n",
    "print \"res dual: \",res\n",
    "print \"lambdas: \", l.value.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong duality holds, and thus the following KKT conditions are satisfied:\n",
    "\n",
    "$$\\left\\{ \\begin{array}{rl}\n",
    " Ax^* - 1>=0 \\\\\n",
    " \\lambda_{1,2} >= 0 \\\\\n",
    " \\frac{\\partial L}{\\partial x}\\left(x^*\\right) = 0 -* \n",
    "       \\end{array} \\right.$$\n",
    "       \n",
    "\\* - holds because of the equations on the partial derivatives above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.55066088e-06]\n",
      " [  2.14287698e-01]]\n"
     ]
    }
   ],
   "source": [
    "print A.dot(x.value) - 1 # greater than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"5_a.png\" width=\"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5_b.png\" width=\"65%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
